# Reservoir Surrogate Modeling Project - Complete Overview

**Date**: 2025-10-30
**Goal**: Build a GNN-LSTM surrogate model to predict reservoir production rates 1000Ã— faster than physics-based simulation
**Status**: Phase 2 complete (data generation), Phase 3 in progress (ML training pipeline)

---

## Table of Contents

1. [Project Motivation](#project-motivation)
2. [Overall Workflow](#overall-workflow)
3. [Phase 1: Reservoir Model Generation](#phase-1-reservoir-model-generation)
4. [Phase 2: Simulation Data Generation](#phase-2-simulation-data-generation)
5. [Phase 3: Surrogate Model Development](#phase-3-surrogate-model-development)
6. [Phase 4: Model Deployment](#phase-4-model-deployment)
7. [Technical Details](#technical-details)
8. [File Organization](#file-organization)

---

## Project Motivation

### The Challenge
Reservoir simulation is critical for optimizing oil/gas production, but **physics-based simulators are extremely slow**:
- Full reservoir simulation: **~50 seconds per run**
- Optimization requires: **1000+ simulation runs**
- Total time for optimization: **~14 hours**

### Our Solution
Build a **GNN-LSTM surrogate model** that:
- Predicts production rates in **~0.05 seconds** (1000Ã— speedup)
- Maintains **<5% prediction error** (MAPE)
- Enables real-time production optimization

### Why GNN-LSTM?
- **GNN (Graph Neural Network)**: Captures spatial well connectivity and heterogeneity
- **LSTM (Long Short-Term Memory)**: Models temporal dynamics of production
- **Superior to baseline**: Enhanced with 10-dimensional edge features vs. paper's 1-dim

---

## Overall Workflow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         COMPLETE WORKFLOW                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

PHASE 1: RESERVOIR MODEL GENERATION (COMPLETE âœ“)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Input: config.yaml (reservoir properties)
           â†“
    [src/reservoir_model.py]
           â†“
    Output:
    â€¢ data/permeability_field.npy (100Ã—100 grid)
    â€¢ data/porosity_field.npy (100Ã—100 grid)
    â€¢ data/well_locations.csv (10 producers + 5 injectors)
           â†“

PHASE 2: SIMULATION DATA GENERATION (COMPLETE âœ“)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Input: Reservoir model + LHS sampling (100 scenarios)
           â†“
    [utils/doe_sampler.py] â†’ Generate 100 parameter combinations
           â†“
    [utils/scenario_runner.py] â†’ Run IMPES simulator for each
           â†“
    [simulator/IMPES_phase1.py] â†’ Physics-based simulation
           â€¢ Solves pressure equation (Poisson)
           â€¢ Solves saturation transport (Buckley-Leverett)
           â€¢ 6 months, Î”t adaptive
           â†“
    Output:
    â€¢ results/training_data/doe_001/doe_001.npz (61 timesteps)
    â€¢ results/training_data/doe_002/doe_002.npz
    â€¢ ... (100 total scenarios)
           â†“

PHASE 3: SURROGATE MODEL DEVELOPMENT (IN PROGRESS â³)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Input: 100 NPZ simulation files
           â†“
    [ml/data/preprocessing.py] â†’ Compute edge features
           â€¢ Static: distance, permeability, transmissibility
           â€¢ Dynamic: pressure/saturation gradients
           â€¢ Data-driven: time-lagged correlations
           â†“
    [ml/data/dataset.py] â†’ PyTorch Dataset (70/15/15 split)
           â†“
    [ml/models/surrogate.py] â†’ GNN-LSTM Architecture
           â€¢ GNN: Spatial encoding (well connectivity)
           â€¢ LSTM: Temporal encoding (production dynamics)
           â€¢ Decoder: Predict oil + water rates (20 outputs)
           â†“
    [ml/training/trainer.py] â†’ Training Loop
           â€¢ Loss: Weighted L1 (Î²=80 for oil, Î±=1 for water)
           â€¢ 150 epochs, ~6 hours on GPU
           â€¢ Early stopping, checkpointing
           â†“
    Output:
    â€¢ results/ml_experiments/gnn_lstm_baseline/best_model.pth
    â€¢ Training curves, metrics
           â†“

PHASE 4: MODEL DEPLOYMENT (PLANNED ğŸ“)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Input: Trained surrogate model
           â†“
    [Optimization Loop]
           â€¢ PSO/Genetic Algorithm
           â€¢ Surrogate predicts production (0.05s)
           â€¢ Find optimal injection strategy
           â†“
    Output: Optimal well control schedule
```

---

## Phase 1: Reservoir Model Generation

### Purpose
Create a realistic heterogeneous reservoir with strategically placed wells.

### Location
- **Script**: `src/reservoir_model.py`
- **Config**: `config.yaml`
- **Output**: `data/` directory

### What It Does

#### 1. Permeability Field Generation
```python
# Spatially correlated log-normal distribution
# Method: Gaussian Random Field with exponential covariance
# Parameters:
#   - Mean: 100 mD (millidarcy)
#   - Range: [18, 650] mD
#   - Correlation length: 500 m
#   - Grid: 100Ã—100 cells, 50m Ã— 50m each
```

**Key Algorithm**: FFT-based spectral method for efficiency
- Generates correlated Gaussian field: `C(r) = ÏƒÂ² * exp(-r / Î»)`
- Transforms to log-normal: `k = exp(Gaussian_field)`
- Ensures realistic heterogeneity (some zones are 30Ã— more permeable)

#### 2. Porosity Field Generation
```python
# Correlated with permeability using Kozeny-Carman-like relationship
# Ï† = Ï†_mean + Î± * (log(k) - log(k_mean))
# Parameters:
#   - Mean: 0.25 (25%)
#   - Correlation coefficient: 0.6 with permeability
```

#### 3. Well Placement Strategy
```python
# 10 Producers + 5 Injectors
# Constraints:
#   - Minimum spacing: 1000 m (avoid interference)
#   - Producers: High permeability zones (better production)
#   - Injectors: Strategically placed for sweep efficiency
#   - Pattern: Modified five-spot (optimal for waterflooding)
```

**Algorithm**:
1. Score each grid cell by permeability
2. Select producers from high-k regions (spaced â‰¥1000m apart)
3. Place injectors to maximize geometric sweep (Voronoi-based)

### Files Generated
```
data/
â”œâ”€â”€ permeability_field.npy      # (100, 100) float64, mD
â”œâ”€â”€ porosity_field.npy          # (100, 100) float64, fraction
â”œâ”€â”€ well_locations.csv          # 15 rows (10P + 5I), columns: x, y, type
â””â”€â”€ reservoir_config.json       # Metadata (grid size, domain, stats)
```

### Visualization
```bash
python src/reservoir_model.py
# Generates: results/reservoir_visualization.png
#   - Subplot 1: Permeability field (colormap: log scale)
#   - Subplot 2: Porosity field
#   - Subplot 3: Well locations overlaid on permeability
```

---

## Phase 2: Simulation Data Generation

### Purpose
Generate 100 diverse training scenarios using Latin Hypercube Sampling (LHS) to explore the parameter space.

### Location
- **Main Script**: `utils/scenario_runner.py`
- **DOE Sampler**: `utils/doe_sampler.py`
- **Simulator**: `simulator/IMPES_phase1.py`
- **Batch Runner**: `utils/batch_simulator.py`

### What It Does

#### 1. Design of Experiments (DOE) with LHS
```python
# Latin Hypercube Sampling (LHS)
# Purpose: Efficiently explore 7-dimensional parameter space
#
# Varying Parameters (per scenario):
#   1. Injector 1 rate: [300, 800] STB/day
#   2. Injector 2 rate: [300, 800] STB/day
#   3. Injector 3 rate: [300, 800] STB/day
#   4. Injector 4 rate: [300, 800] STB/day
#   5. Injector 5 rate: [300, 800] STB/day
#   6. Producer BHP: [1500, 2500] psi (same for all 10 producers)
#   7. (Optional) Initial pressure: [2800, 3200] psi
```

**Why LHS?**
- Better space-filling than random sampling
- Ensures coverage of extreme cases (corners of hypercube)
- 100 samples provide good representation of 7D space
- Each dimension divided into 100 strata, one sample per stratum

**Code Location**: `utils/doe_sampler.py`
```python
sampler = LHSSampler(n_samples=100, seed=42)
scenarios = sampler.generate_scenarios(
    param_ranges={
        'inj1_rate': (300, 800),
        'inj2_rate': (300, 800),
        ...
    }
)
```

#### 2. IMPES Two-Phase Simulator
```python
# Implicit Pressure, Explicit Saturation (IMPES)
# Solves two coupled equations:
#
# 1. Pressure Equation (Implicit):
#    âˆ‡ Â· (Î»_t * k * âˆ‡P) = q_wells + âˆ‚/âˆ‚t(Ï† * S_w)
#    where Î»_t = Î»_o + Î»_w (total mobility)
#
# 2. Saturation Equation (Explicit):
#    Ï† * âˆ‚S_w/âˆ‚t + âˆ‡ Â· (f_w * v_t) = q_w
#    where f_w = fractional flow of water
```

**Key Components**:

a) **Pressure Solver** (`simulator/IMPES_phase1.py:300-450`):
   - Assembles coefficient matrix with 7-point stencil
   - Incorporates gravity terms: `Ï_phase * g * Î”z`
   - Handles well terms: `q_well = PI * (P_wf - P_cell)`
   - Solves with scipy sparse solver (LGMRES)

b) **Saturation Transport** (`simulator/IMPES_phase1.py:450-600`):
   - Upstream weighting for stability
   - Buckley-Leverett fractional flow: `f_w = Î»_w / (Î»_w + Î»_o)`
   - Capillary pressure effects: `P_c(S_w) = P_e * (S_w)^(-1/Î»)`
   - Adaptive timesteping based on CFL condition

c) **Relative Permeability** (`simulator/rel_perm.py`):
   - Corey-type correlations:
     ```
     k_rw = k_rw_max * ((S_w - S_wc) / (1 - S_wc - S_or))^n_w
     k_ro = k_ro_max * ((1 - S_w - S_or) / (1 - S_wc - S_or))^n_o
     ```
   - Parameters: S_wc=0.2, S_or=0.2, n_w=2.0, n_o=2.0

d) **Well Model** (`simulator/prodindex.py`):
   - Peaceman productivity index: `PI = 2Ï€kh / (Î¼ * ln(r_e/r_w))`
   - Handles rate-constrained injectors (fixed q)
   - Handles BHP-constrained producers (fixed P_wf)

**Simulation Settings**:
- Duration: 6 months (180 days)
- Timesteps: Adaptive (CFL â‰¤ 0.5), typically ~61 timesteps
- Grid: 100Ã—100 cells (5 km Ã— 5 km domain)
- Phases: Oil (Î¼_o=2 cp) + Water (Î¼_w=0.5 cp)

#### 3. Parallel Execution
```bash
# Run 100 scenarios in parallel using GNU Parallel
parallel -j 8 --joblog parallel_joblog.tsv \
    python utils/scenario_runner.py --scenario_id {} \
    ::: {1..100}

# Monitoring
bash monitor_batch.sh  # Tracks progress, ETA
```

**Runtime**:
- Single scenario: ~50 seconds
- 100 scenarios (8 parallel): ~12 minutes
- Total compute: ~83 CPU-minutes

#### 4. Output Format
Each scenario generates an NPZ file:
```python
# results/training_data/doe_001/doe_001.npz
#
# Arrays stored:
np.savez(
    'doe_001.npz',

    # Time dimension
    times=np.array([0, 3, 6, ..., 180]),  # (61,) days

    # Pressure field (spatial + temporal)
    pressure=np.array(...),     # (61, 100, 100) psi
    saturation=np.array(...),   # (61, 100, 100) fraction

    # Well production (per timestep)
    producer_oil_rates=np.array(...),    # (61, 10) STB/day
    producer_water_rates=np.array(...),  # (61, 10) STB/day
    producer_bhp=np.array(...),          # (61, 10) psi

    # Injection (constant per scenario)
    injector_rates=np.array([500, 600, ...]),  # (5,) STB/day

    # Cumulative production
    cumulative_oil=np.array(...),   # (61, 10) STB
    cumulative_water=np.array(...), # (61, 10) STB

    # Reservoir properties (static)
    permeability=np.array(...),  # (100, 100) mD
    porosity=np.array(...),      # (100, 100) fraction

    # Well locations
    producer_coords=np.array(...),  # (10, 2) x, y in meters
    injector_coords=np.array(...),  # (5, 2) x, y in meters
)
```

### Files Generated
```
results/training_data/
â”œâ”€â”€ doe_001/
â”‚   â”œâ”€â”€ doe_001.npz           # Simulation output (~450 KB per file)
â”‚   â””â”€â”€ input_file_phase1.py  # Generated input (copy for reproducibility)
â”œâ”€â”€ doe_002/
â”‚   â”œâ”€â”€ doe_002.npz
â”‚   â””â”€â”€ input_file_phase1.py
â”œâ”€â”€ ...
â””â”€â”€ doe_100/
    â”œâ”€â”€ doe_100.npz
    â””â”€â”€ input_file_phase1.py

Total: ~45 MB (100 scenarios)
```

---

## Phase 3: Surrogate Model Development

### Purpose
Train a GNN-LSTM neural network to predict production rates given injection controls and reservoir properties.

### Location
- **Models**: `ml/models/` (gnn.py, lstm.py, surrogate.py, losses.py)
- **Data**: `ml/data/` (graph_builder.py, preprocessing.py, dataset.py, normalizers.py)
- **Training**: `ml/training/` (trainer.py, evaluator.py, config.yaml)
- **Scripts**: `ml/scripts/` (train.py, evaluate.py, preprocess_all.py)

### Architecture Overview

```
INPUT FEATURES (per timestep t):
â”œâ”€â”€ Producer Nodes (10 wells, 10-dim each):
â”‚   [BHP, k, Ï†, depth, x, y, cum_oil, cum_water, prev_oil_rate, prev_water_rate]
â”‚
â”œâ”€â”€ Injector Nodes (5 wells, 8-dim each):
â”‚   [rate, k, Ï†, depth, x, y, cum_inj, prev_rate]
â”‚
â””â”€â”€ Edge Features (10-dim, computed between all connected wells):
    [inv_distance, log_k_avg, log_k_contrast, cos_angle, sin_angle,
     transmissibility, time_lag_corr, Î”P, Î”Sw, drainage_overlap]

                              â†“

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GNN-LSTM SURROGATE MODEL                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

STEP 1: SPATIAL ENCODING (per timestep t)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    [DualGraphGNN]
        â”œâ”€â”€ P2P Graph (Producer-Producer, Voronoi connectivity)
        â”‚   â””â”€â”€ EnhancedGNN(3 layers, hidden=128)
        â”‚       â€¢ Message: concat(node_i, node_j, edge_ij)
        â”‚       â€¢ Aggregate: sum over neighbors
        â”‚       â€¢ Update: MLP + PReLU + residual
        â”‚
        â”œâ”€â”€ I2P Graph (Injector-Producer, bipartite full/k-nearest)
        â”‚   â””â”€â”€ EnhancedGNN(3 layers, hidden=128)
        â”‚
        â””â”€â”€ Fusion: Linear(256 â†’ 128)
            Output: (batch, num_prod=10, emb=128) per timestep

STEP 2: STACK TEMPORAL SEQUENCE
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Stack GNN outputs for T=61 timesteps:
    Shape: (batch, T=61, num_prod=10, emb=128)

STEP 3: TEMPORAL ENCODING
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    [WellAwareLSTM]
        â€¢ Flatten: (batch, T, num_prod*emb) = (batch, 61, 1280)
        â€¢ LSTM(2 layers, hidden=256):
            h_t = LSTM(flatten(GNN_outputs_t), h_{t-1})
        â€¢ Output: (batch, T=61, hidden=256)

STEP 4: RATE PREDICTION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    [RateDecoder]
        â€¢ MLP: 256 â†’ 64 â†’ 20
        â€¢ Activation: Softplus (ensure positive rates)
        â€¢ Output: (batch, T=61, 20)
            â”œâ”€â”€ oil_rates: [:, :, :10]  â†’ 10 producers
            â””â”€â”€ water_rates: [:, :, 10:]  â†’ 10 producers

OUTPUT:
    Predicted production rates for all producers over 6 months
```

### Model Size
```
Total Parameters: ~2.5M
â”œâ”€â”€ DualGraphGNN: ~1.2M
â”œâ”€â”€ WellAwareLSTM: ~1.0M
â””â”€â”€ RateDecoder: ~0.3M

Model file: ~10 MB (FP32)
Inference time: 0.05 seconds (on CPU)
```

### Training Strategy

#### Loss Function
```python
L_total = Î²Â·L_oil + Î±Â·L_water + Î»_cumÂ·L_cumulative + Î»_physÂ·L_physics

where:
    Î² = 80.0   # Oil is economically important (from SPE-215842 paper)
    Î± = 1.0    # Water weight
    Î»_cum = 0.1   # Cumulative production accuracy
    Î»_phys = 0.01 # Physics constraints (monotonicity, smoothness)

L_oil = (1/N) Î£ |pred_oil - actual_oil|  # Weighted L1 loss
L_cumulative = MSE(cumsum(pred), cumsum(actual))
L_physics = penalty for violations (negative rates, non-monotonic cumulative)
```

#### Hyperparameters
```yaml
# From ml/training/config.yaml
batch_size: 8
num_epochs: 150
learning_rate: 1e-4
optimizer: Adam
weight_decay: 1e-5
gradient_clip: 1.0

lr_scheduler:
  type: StepLR
  step_size: 50
  gamma: 0.8

early_stopping:
  patience: 15
  min_delta: 0.001
```

#### Data Split
```python
train_scenarios = 70  # 70% for training
val_scenarios = 15    # 15% for validation
test_scenarios = 15   # 15% for testing (final evaluation)

# Stratified split ensures coverage of parameter space
```

### Training Workflow

```bash
# 1. Preprocess data (one-time, ~30 minutes)
python ml/scripts/preprocess_all.py \
    --data_dir results/training_data \
    --output_dir ml/data/preprocessed \
    --num_scenarios 100

# Output:
#   ml/data/preprocessed/graph_data.npz
#   ml/data/preprocessed/static_features.npz
#   ml/data/preprocessed/normalizers.pkl

# 2. Train model (~6 hours on GPU, ~24 hours on CPU)
python ml/scripts/train.py \
    --config ml/training/config.yaml \
    --exp_name gnn_lstm_baseline

# Output:
#   results/ml_experiments/gnn_lstm_baseline/
#   â”œâ”€â”€ best_model.pth         # Best validation loss checkpoint
#   â”œâ”€â”€ checkpoint_epoch_*.pth # Periodic checkpoints
#   â”œâ”€â”€ train.log              # Training progress
#   â””â”€â”€ metrics.csv            # Loss history

# 3. Evaluate on test set (~10 minutes)
python ml/scripts/evaluate.py \
    --checkpoint results/ml_experiments/gnn_lstm_baseline/best_model.pth \
    --data_dir results/training_data \
    --output_dir results/ml_experiments/gnn_lstm_baseline/evaluation

# Output:
#   evaluation/
#   â”œâ”€â”€ metrics_summary.json   # MAPE, RÂ², cumulative error
#   â”œâ”€â”€ predictions/           # NPZ files with predictions
#   â””â”€â”€ plots/                 # Rate comparison plots
```

### Expected Performance

| Metric | Target | Notes |
|--------|--------|-------|
| **Oil Rate MAPE** | < 5% | Mean Absolute Percentage Error |
| **Water Rate MAPE** | < 6% | Slightly higher (smaller magnitudes) |
| **Cumulative Oil Error** | < 3% | Total production accuracy |
| **RÂ² Score** | > 0.95 | Coefficient of determination |
| **Inference Speed** | 0.05 s | vs. 50 s for simulator (1000Ã— speedup) |
| **Training Time** | 6 hours | RTX 2060 GPU, 150 epochs |
| **Model Size** | 10 MB | FP32 weights |

---

## Phase 4: Model Deployment

### Purpose
Use the trained surrogate for real-time optimization and decision-making.

### Workflow

```
PRODUCTION OPTIMIZATION LOOP
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Input: Current reservoir state
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Optimization Algorithm      â”‚
â”‚  (PSO / Genetic / Gradient)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
   Propose injection schedule
   (5 injector rates over 6 months)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Surrogate Model Prediction  â”‚
â”‚  (0.05 seconds)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
   Predicted oil/water production
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Objective Function          â”‚
â”‚  J = Î£(revenue_oil - cost)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
   Fitness score
       â†“
   Update population â†’ Repeat
       â†“
   (After 1000 evaluations)
       â†“
   Optimal injection strategy

Total optimization time:
    1000 evals Ã— 0.05 s = 50 seconds

vs. Physics-based:
    1000 evals Ã— 50 s = 14 hours

Speedup: 1000Ã—
```

### Use Cases

1. **Production Optimization**
   - Maximize NPV (Net Present Value)
   - Balance oil production vs. water handling costs
   - Find optimal injection rates per well

2. **Real-Time Decision Support**
   - Predict impact of changing injection rates
   - "What-if" scenarios for field management
   - Constraint handling (max injection capacity)

3. **Uncertainty Quantification**
   - Ensemble predictions (train multiple models)
   - Confidence intervals on production forecasts
   - Risk assessment for investment decisions

4. **Closed-Loop Reservoir Management**
   - Integrate with SCADA systems
   - Automatically adjust injection based on real-time data
   - Model predictive control (MPC) for wells

---

## Technical Details

### Mathematical Formulation

#### Reservoir Simulation (IMPES)

**Pressure Equation** (Implicit):
```
âˆ‡ Â· (Î»_t(S_w) * k * (âˆ‡P - Ï_phase * g * âˆ‡z)) = q_wells + (Ï†/Î”t) * (S_w^{n+1} - S_w^n)

where:
    Î»_t = k_rw/Î¼_w + k_ro/Î¼_o  (total mobility)
    k = permeability tensor
    P = pressure field
    Ï_phase = fluid density
    g = gravity (9.81 m/sÂ²)
    q_wells = well source/sink terms
```

**Saturation Equation** (Explicit):
```
Ï† * âˆ‚S_w/âˆ‚t + âˆ‡ Â· (f_w(S_w) * v_t) = q_w

where:
    f_w = Î»_w / Î»_t  (fractional flow of water)
    v_t = -Î»_t * k * (âˆ‡P - Ï_avg * g * âˆ‡z)  (total velocity)
    q_w = water injection/production
```

**Discretization**:
- Spatial: Finite volume method (7-point stencil)
- Temporal: Forward Euler for saturation, backward Euler for pressure
- Upwind scheme for saturation transport (stability)

#### GNN Message Passing

**Edge Convolution** (per layer l):
```
h_i^{l+1} = Ïƒ( W_self^l * h_i^l + Î£_{jâˆˆN(i)} W_msg^l * m_ij )

where:
    m_ij = MLP( concat(h_i^l, h_j^l, e_ij) )
    e_ij = 10-dim edge features
    N(i) = neighbors of node i
    Ïƒ = PReLU activation
```

**Message aggregation**:
```python
# Sum aggregation (alternative: mean, max)
aggregate = Î£_{jâˆˆneighbors} message_ij

# Update with residual connection
h_new = h_old + MLP(aggregate)
```

#### LSTM Temporal Modeling

**Standard LSTM equations**:
```
f_t = Ïƒ(W_f Â· [h_{t-1}, x_t] + b_f)    (forget gate)
i_t = Ïƒ(W_i Â· [h_{t-1}, x_t] + b_i)    (input gate)
g_t = tanh(W_g Â· [h_{t-1}, x_t] + b_g) (candidate)
o_t = Ïƒ(W_o Â· [h_{t-1}, x_t] + b_o)    (output gate)

c_t = f_t âŠ™ c_{t-1} + i_t âŠ™ g_t        (cell state)
h_t = o_t âŠ™ tanh(c_t)                   (hidden state)
```

**Our modification (WellAwareLSTM)**:
```python
# Flatten spatial wells per timestep
x_t = flatten([h_well1, h_well2, ..., h_well10])  # (1280-dim)

# Process through LSTM
h_t, c_t = LSTM(x_t, h_{t-1}, c_{t-1})  # (256-dim)

# Maintains temporal coherence across all wells
```

### Data Statistics

#### Reservoir Properties
```
Permeability:
    Mean: 100 mD
    Range: [18, 650] mD
    Std: 95 mD
    Distribution: Log-normal

Porosity:
    Mean: 0.25
    Range: [0.20, 0.32]
    Std: 0.028
    Distribution: Normal (correlated with k)

Domain:
    Size: 5 km Ã— 5 km
    Depth: 2000 m (average)
    Grid: 100Ã—100 cells (50m Ã— 50m each)
```

#### Well Configuration
```
Producers (10 wells):
    Control: Fixed BHP (1500-2500 psi, varies by scenario)
    Typical rates: 50-200 STB/day oil, 20-100 STB/day water
    Total oil production: ~30,000 STB over 6 months (per scenario)

Injectors (5 wells):
    Control: Fixed rate (300-800 STB/day, varies by scenario)
    Total injection: ~90,000 STB over 6 months (per scenario)

Recovery:
    Water cut: Increases from 0% to 30-60% over 6 months
    Oil recovery factor: ~5-10% OOIP (Original Oil In Place)
```

#### Training Data
```
Scenarios: 100
Timesteps per scenario: 61 (adaptive timestep)
Total datapoints: 100 Ã— 61 Ã— 10 = 61,000 (wells Ã— time)

Features per datapoint:
    Node features: 10 (prod) + 5 (inj) = 15 nodes
    Edge features: ~70 edges Ã— 10-dim = 700 features
    Targets: 2 rates Ã— 10 producers = 20 outputs

Training set: 70 scenarios (42,700 datapoints)
Validation set: 15 scenarios (9,150 datapoints)
Test set: 15 scenarios (9,150 datapoints)
```

---

## File Organization

### Complete Directory Structure

```
surrogate-modelling-1/
â”‚
â”œâ”€â”€ README.md                  # Quick start guide
â”œâ”€â”€ PROJECT_OVERVIEW.md        # This file (comprehensive documentation)
â”œâ”€â”€ config.yaml                # Reservoir configuration
â”œâ”€â”€ requirements-simulator.txt # Python dependencies for simulator
â”œâ”€â”€ requirements-ml.txt        # Python dependencies for ML
â”‚
â”œâ”€â”€ src/                       # Reservoir Model Generation (PHASE 1)
â”‚   â””â”€â”€ reservoir_model.py     # Generate permeability, porosity, wells
â”‚
â”œâ”€â”€ simulator/                 # IMPES Two-Phase Simulator (PHASE 2)
â”‚   â”œâ”€â”€ IMPES_phase1.py        # Main simulator (pressure + saturation)
â”‚   â”œâ”€â”€ rel_perm.py            # Relative permeability curves
â”‚   â”œâ”€â”€ cap_press.py           # Capillary pressure
â”‚   â”œâ”€â”€ prodindex.py           # Well productivity index
â”‚   â”œâ”€â”€ updatewells.py         # Well constraint handling
â”‚   â”œâ”€â”€ fluid_properties.py    # Oil/water properties
â”‚   â”œâ”€â”€ petrophysics.py        # Rock properties
â”‚   â”œâ”€â”€ myarrays.py            # Array manipulation utilities
â”‚   â””â”€â”€ spdiaginv.py           # Sparse matrix utilities
â”‚
â”œâ”€â”€ utils/                     # Batch Simulation & Analysis
â”‚   â”œâ”€â”€ doe_sampler.py         # Latin Hypercube Sampling (LHS)
â”‚   â”œâ”€â”€ scenario_runner.py     # Single scenario execution
â”‚   â”œâ”€â”€ batch_simulator.py     # Parallel batch execution
â”‚   â””â”€â”€ generate_visualizations.py  # Plot results
â”‚
â”œâ”€â”€ ml/                        # Surrogate Model (PHASE 3)
â”‚   â”‚
â”‚   â”œâ”€â”€ README.md              # ML architecture documentation
â”‚   â”œâ”€â”€ IMPLEMENTATION_STATUS.md  # Development progress
â”‚   â”œâ”€â”€ TESTING_STATUS.md      # Module test results
â”‚   â”œâ”€â”€ NEXT_STEPS.md          # Implementation guide
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                  # Data preprocessing
â”‚   â”‚   â”œâ”€â”€ graph_builder.py   # Well connectivity (Voronoi)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py   # 10-dim edge features
â”‚   â”‚   â”œâ”€â”€ normalizers.py     # Feature scaling
â”‚   â”‚   â””â”€â”€ dataset.py         # PyTorch Dataset
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                # Neural network models
â”‚   â”‚   â”œâ”€â”€ gnn.py             # Enhanced GNN with edge features
â”‚   â”‚   â”œâ”€â”€ lstm.py            # Temporal LSTM variants
â”‚   â”‚   â”œâ”€â”€ surrogate.py       # Full GNN-LSTM model
â”‚   â”‚   â””â”€â”€ losses.py          # Weighted + physics-informed loss
â”‚   â”‚
â”‚   â”œâ”€â”€ training/              # Training infrastructure
â”‚   â”‚   â”œâ”€â”€ config.yaml        # Hyperparameters
â”‚   â”‚   â”œâ”€â”€ trainer.py         # Training loop (to be completed)
â”‚   â”‚   â””â”€â”€ evaluator.py       # Metrics & evaluation (to be completed)
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                 # ML utilities
â”‚   â”‚   â”œâ”€â”€ helpers.py         # Checkpointing, early stopping
â”‚   â”‚   â””â”€â”€ visualization.py   # Plotting (to be completed)
â”‚   â”‚
â”‚   â””â”€â”€ scripts/               # Entry points
â”‚       â”œâ”€â”€ preprocess_all.py  # Data preprocessing (to be completed)
â”‚       â”œâ”€â”€ train.py           # Main training script (to be completed)
â”‚       â””â”€â”€ evaluate.py        # Model evaluation (to be completed)
â”‚
â”œâ”€â”€ data/                      # Reservoir Model Outputs (PHASE 1)
â”‚   â”œâ”€â”€ permeability_field.npy # 100Ã—100 grid
â”‚   â”œâ”€â”€ porosity_field.npy     # 100Ã—100 grid
â”‚   â”œâ”€â”€ well_locations.csv     # 15 wells (10P + 5I)
â”‚   â”œâ”€â”€ reservoir_config.json  # Metadata
â”‚   â””â”€â”€ impes_input/           # Simulator inputs
â”‚       â”œâ”€â”€ selected_wells.csv
â”‚       â”œâ”€â”€ well_locations_ft.csv
â”‚       â”œâ”€â”€ schedule_injector_rates.csv
â”‚       â””â”€â”€ schedule_producer_bhp.csv
â”‚
â”œâ”€â”€ scenarios/                 # DOE Sample Definitions
â”‚   â”œâ”€â”€ scenario_001.yaml      # Parameter set for doe_001
â”‚   â”œâ”€â”€ scenario_002.yaml
â”‚   â””â”€â”€ ... (100 total)
â”‚
â”œâ”€â”€ results/                   # Simulation & ML Outputs
â”‚   â”œâ”€â”€ reservoir_visualization.png  # PHASE 1 output
â”‚   â”‚
â”‚   â”œâ”€â”€ training_data/         # PHASE 2 outputs (100 scenarios)
â”‚   â”‚   â”œâ”€â”€ doe_001/
â”‚   â”‚   â”‚   â”œâ”€â”€ doe_001.npz    # Simulation results (~450 KB)
â”‚   â”‚   â”‚   â””â”€â”€ input_file_phase1.py
â”‚   â”‚   â”œâ”€â”€ doe_002/
â”‚   â”‚   â””â”€â”€ ... (doe_100/)
â”‚   â”‚
â”‚   â””â”€â”€ ml_experiments/        # PHASE 3 outputs
â”‚       â””â”€â”€ gnn_lstm_baseline/
â”‚           â”œâ”€â”€ best_model.pth
â”‚           â”œâ”€â”€ checkpoints/
â”‚           â”œâ”€â”€ logs/
â”‚           â””â”€â”€ evaluation/
â”‚
â””â”€â”€ docs/                      # Additional Documentation
    â”œâ”€â”€ CODEBASE_ANALYSIS.md   # Code quality report
    â”œâ”€â”€ CLEANUP_CHECKLIST.md   # Cleanup instructions
    â””â”€â”€ ANALYSIS_INDEX.md      # Quick reference
```

### Key Files Reference

| File | Purpose | Size | Status |
|------|---------|------|--------|
| `src/reservoir_model.py` | Generate reservoir model | 500 lines | âœ“ Complete |
| `simulator/IMPES_phase1.py` | Physics-based simulator | 800 lines | âœ“ Complete |
| `utils/doe_sampler.py` | LHS parameter sampling | 150 lines | âœ“ Complete |
| `utils/scenario_runner.py` | Single scenario execution | 200 lines | âœ“ Complete |
| `utils/batch_simulator.py` | Parallel batch runner | 180 lines | âœ“ Complete |
| `ml/models/surrogate.py` | GNN-LSTM model | 280 lines | âœ“ Complete |
| `ml/training/trainer.py` | Training loop | - | â³ To implement |
| `ml/scripts/train.py` | Training entry point | - | â³ To implement |

---

## Current Status & Next Steps

### Completed (âœ“)

#### Phase 1: Reservoir Model âœ“
- Heterogeneous permeability field (log-normal, spatially correlated)
- Correlated porosity field
- Strategic well placement (10 producers + 5 injectors)
- Validated with visualization

#### Phase 2: Simulation Data âœ“
- 100 diverse scenarios using LHS
- IMPES two-phase simulator fully functional
- Parallel batch execution (8 cores)
- Total: ~45 MB of training data (100 Ã— 450 KB)

#### Phase 3: ML Infrastructure (85% complete) âœ“
- âœ… All data preprocessing modules (graph_builder, preprocessing, normalizers, dataset)
- âœ… All neural network models (gnn, lstm, surrogate, losses)
- âœ… Configuration system (config.yaml)
- âœ… Utilities (checkpointing, early stopping)
- âœ… Comprehensive documentation (README, status docs)

### In Progress (â³)

#### Phase 3: Training Pipeline (15% remaining)
- â³ `ml/training/trainer.py` - Training loop with validation
- â³ `ml/training/evaluator.py` - Metrics computation
- â³ `ml/scripts/preprocess_all.py` - Automated preprocessing
- â³ `ml/scripts/train.py` - Training entry point
- â³ `ml/scripts/evaluate.py` - Evaluation script
- â³ `ml/utils/visualization.py` - Plotting utilities

**Estimated completion**: 10-15 hours of focused work

### Planned (ğŸ“)

#### Phase 4: Deployment
- Integration with optimization algorithms (PSO, Genetic)
- Real-time inference API
- Uncertainty quantification
- Model monitoring and retraining pipeline

---

## Performance Benchmarks

### Simulation (Physics-Based)

| Metric | Value |
|--------|-------|
| Single scenario runtime | 50 seconds |
| Grid cells | 10,000 (100Ã—100) |
| Timesteps | 61 (adaptive) |
| Phases | 2 (oil + water) |
| Memory usage | ~500 MB |

### Surrogate Model (ML-Based)

| Metric | Target | Achieved |
|--------|--------|----------|
| Inference time | < 0.1 s | TBD (after training) |
| Oil MAPE | < 5% | TBD |
| Water MAPE | < 6% | TBD |
| RÂ² score | > 0.95 | TBD |
| Model size | ~10 MB | âœ“ |
| Speedup vs simulator | 1000Ã— | TBD |

### Data Generation

| Metric | Value |
|--------|-------|
| Scenarios | 100 |
| Total simulation time | 83 CPU-minutes (8 cores) |
| Data generated | 45 MB (compressed) |
| Parameters varied | 7 (5 injection rates + 1 BHP + 1 P_init) |

---

## References & Citations

### Papers
1. **Huang, H., Gong, B., & Sun, W.** (2023). "A Deep-Learning-Based Graph Neural Network-Long-Short-Term Memory Model for Reservoir Simulation and Optimization With Varying Well Controls." *SPE Journal*, SPE-215842-PA.
   - **Our enhancement**: 10-dim edge features vs. 1-dim (distance only)

2. **Aziz, K., & Settari, A.** (1979). "Petroleum Reservoir Simulation." *Elsevier Applied Science*.
   - Classical reference for IMPES formulation

3. **Gilman, J. R., & Kazemi, H.** (1983). "Improvements in Simulation of Naturally Fractured Reservoirs." *SPE Journal*, 23(4), 695-707.
   - Well productivity index (Peaceman model)

### Software
- **PyTorch** (2.9.0): Deep learning framework
- **PyTorch Geometric** (2.7.0): Graph neural network library
- **SciPy** (1.16.3): Sparse linear solvers (LGMRES)
- **NumPy** (2.3.4): Numerical arrays

### Algorithms
- **Latin Hypercube Sampling**: McKay et al. (1979) for DOE
- **IMPES**: Implicit Pressure Explicit Saturation (Stone & Garder, 1961)
- **Voronoi Diagrams**: Fortune's algorithm (1987) for well connectivity
- **Message Passing Neural Networks**: Gilmer et al. (2017)

---

## Troubleshooting & FAQ

### Q1: Simulation fails with "Matrix singular" error
**A**: The pressure equation solver failed. Possible causes:
- Permeability too heterogeneous (check min/max k)
- Wells too close together (check spacing constraint)
- Timestep too large (reduce Î”t_max in config)

**Fix**:
```python
# In config.yaml
simulation:
  timestep:
    dt_max: 1.0  # Reduce from 5.0
  solver:
    tolerance: 1e-6  # Increase tolerance
```

### Q2: LSTM training diverges (NaN loss)
**A**: Gradient explosion. Solutions:
- Reduce learning rate: `1e-4 â†’ 5e-5`
- Increase gradient clipping: `1.0 â†’ 0.5`
- Check feature normalization (especially permeability - use log transform)

### Q3: GNN not capturing spatial patterns
**A**: Edge features may be poorly scaled or connectivity is wrong.
- Verify Voronoi graph has ~4-5 edges per well
- Check edge feature ranges (use `ml/data/preprocessing.py` tests)
- Visualize attention weights (if using AttentionLSTM)

### Q4: Model underfits (high training loss)
**A**: Model capacity may be too small or training too short.
- Increase GNN layers: `3 â†’ 4`
- Increase hidden dimensions: `128 â†’ 256`
- Train longer: `150 â†’ 200 epochs`

### Q5: Model overfits (low train, high val loss)
**A**: Reduce model complexity or increase regularization.
- Increase dropout: `0.2 â†’ 0.3`
- Increase weight decay: `1e-5 â†’ 1e-4`
- Use data augmentation (add noise to inputs)

### Q6: Out of memory during training
**A**: Reduce batch size or model size.
```yaml
training:
  batch_size: 4  # Instead of 8
model:
  gnn:
    hidden_dim: 64  # Instead of 128
```

---

## Contact & Contributions

### Project Status
- **Phase 1**: âœ“ Complete
- **Phase 2**: âœ“ Complete
- **Phase 3**: 85% complete (training pipeline in progress)
- **Phase 4**: Planned

### Next Milestone
Complete ML training pipeline (10-15 hours estimated)

### Documentation Updates
This file is version-controlled. Last updated: 2025-10-30

---

**End of PROJECT_OVERVIEW.md**
